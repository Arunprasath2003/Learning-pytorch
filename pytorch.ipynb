{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_3WxXePxIYw",
        "outputId": "f3b2a920-7bb5-47cc-8bbb-3528a823b453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 662.4636840820312\n",
            "199 470.34429931640625\n",
            "299 334.74005126953125\n",
            "399 239.00933837890625\n",
            "499 171.41693115234375\n",
            "599 123.68536376953125\n",
            "699 89.9743881225586\n",
            "799 66.16264343261719\n",
            "899 49.34124755859375\n",
            "999 37.456703186035156\n",
            "1099 29.059249877929688\n",
            "1199 23.12517738342285\n",
            "1299 18.931455612182617\n",
            "1399 15.967414855957031\n",
            "1499 13.872323989868164\n",
            "1599 12.391338348388672\n",
            "1699 11.34437370300293\n",
            "1799 10.604186058044434\n",
            "1899 10.080852508544922\n",
            "1999 9.710820198059082\n",
            "Result: y = -0.03149085491895676 + 0.8538989424705505 x + 0.005432699806988239 x^2 + -0.09292615205049515 x^3\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "corpus = ['Food is Bad',\n",
        "          'Bad Service Bad Food',\n",
        "          'Food is Good',\n",
        "          'Good Service With Good Food.',\n",
        "          'Service is Bad but Food is Good.']\n",
        "\n",
        "cleaned_corpus = []\n",
        "for sent in corpus:\n",
        "  sent = sent.lower()\n",
        "  cleaned_corpus.append(' '.join([word for word in sent.split() if word not in english_stopwords]))\n",
        "print(cleaned_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFlFDDoI6zCI",
        "outputId": "a3079272-8edf-491d-d172-11c1a6522267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['food bad', 'bad service bad food', 'food good', 'good service good food.', 'service bad food good.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(cleaned_corpus)  ## passing cleaned corpus\n",
        "doc_term_matrix = pd.DataFrame(X.toarray(),columns= vectorizer.get_feature_names_out())\n",
        "print(doc_term_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXMNB4pW7uFc",
        "outputId": "124a5cf0-b4c0-4827-952c-df9f4a1339f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   bad  food  good  service\n",
            "0    1     1     0        0\n",
            "1    2     1     0        1\n",
            "2    0     1     1        0\n",
            "3    0     1     2        1\n",
            "4    1     1     1        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf = TfidfVectorizer()\n",
        "vectors = tf_idf.fit_transform(corpus)\n",
      ],
      "metadata": {
        "id": "F0RBgr8v8FRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
